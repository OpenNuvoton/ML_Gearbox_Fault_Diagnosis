{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce308c7-3188-4b80-a466-7adf36db1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is used for training a autoencoder for gearbox fault diagnosis using TensorFlow and Keras.\n",
    "It imports necessary libraries and modules for data processing, model building, training, and evaluation.\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import load_data\n",
    "import feature_process\n",
    "import c_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36fca62-5126-4b01-b5ae-5e9affb8be91",
   "metadata": {},
   "source": [
    "# Load the GearBox data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c4308b-48d9-4048-a19d-5ca459a7ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PTH1 = \"data/BrokenTooth\"\n",
    "PTH2 = \"data/Healthy\"\n",
    "WIN_LEN = 300  # How many WIN_LEN as 1 feature point\n",
    "INFERENCE_DATA_POINT = 5  # This value should be considered the MCU rom size. 5*300*10*2 = 30000 float points\n",
    "\n",
    "broken_df_train, broken_df_test = load_data.create_test_train_df_from_raw(PTH1, 1, INFERENCE_DATA_POINT, WIN_LEN, (load_data.addcol_load, load_data.addcol_fault))\n",
    "healthy_df_train, healthy_df_test = load_data.create_test_train_df_from_raw(PTH2, 0, INFERENCE_DATA_POINT, WIN_LEN, (load_data.addcol_load, load_data.addcol_fault))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49692bd-ddbb-4eb6-a82e-ba09621efd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>load</th>\n",
       "      <th>fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.350390</td>\n",
       "      <td>1.454870</td>\n",
       "      <td>-1.667080</td>\n",
       "      <td>-2.055610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.452970</td>\n",
       "      <td>1.400100</td>\n",
       "      <td>-2.825100</td>\n",
       "      <td>0.984487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.241284</td>\n",
       "      <td>-0.267390</td>\n",
       "      <td>0.793540</td>\n",
       "      <td>0.605862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.130270</td>\n",
       "      <td>-0.890918</td>\n",
       "      <td>0.696969</td>\n",
       "      <td>0.613068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.296140</td>\n",
       "      <td>0.980479</td>\n",
       "      <td>-1.130560</td>\n",
       "      <td>-0.346971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>-3.443520</td>\n",
       "      <td>-0.361539</td>\n",
       "      <td>-0.376093</td>\n",
       "      <td>-2.447550</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>2.458310</td>\n",
       "      <td>-2.838840</td>\n",
       "      <td>0.191190</td>\n",
       "      <td>-0.201169</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>-0.755909</td>\n",
       "      <td>3.982960</td>\n",
       "      <td>-2.321580</td>\n",
       "      <td>0.749357</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>1.299520</td>\n",
       "      <td>4.402300</td>\n",
       "      <td>-2.232460</td>\n",
       "      <td>0.535038</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>1.179430</td>\n",
       "      <td>-4.292920</td>\n",
       "      <td>0.557745</td>\n",
       "      <td>2.700710</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             a1        a2        a3        a4  load  fault\n",
       "0      2.350390  1.454870 -1.667080 -2.055610   0.0    1.0\n",
       "1      2.452970  1.400100 -2.825100  0.984487   0.0    1.0\n",
       "2     -0.241284 -0.267390  0.793540  0.605862   0.0    1.0\n",
       "3      1.130270 -0.890918  0.696969  0.613068   0.0    1.0\n",
       "4     -1.296140  0.980479 -1.130560 -0.346971   0.0    1.0\n",
       "...         ...       ...       ...       ...   ...    ...\n",
       "14995 -3.443520 -0.361539 -0.376093 -2.447550  90.0    1.0\n",
       "14996  2.458310 -2.838840  0.191190 -0.201169  90.0    1.0\n",
       "14997 -0.755909  3.982960 -2.321580  0.749357  90.0    1.0\n",
       "14998  1.299520  4.402300 -2.232460  0.535038  90.0    1.0\n",
       "14999  1.179430 -4.292920  0.557745  2.700710  90.0    1.0\n",
       "\n",
       "[15000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broken_df_test\n",
    "# broken_df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d813d-a1c4-4ac6-b228-8fb808b6c275",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06dc29ef-f627-48c3-84d9-b94c762f5388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature array shape of healthy point: (3336, 16), (3336,)\n",
      "feature array shape of broken point: (3301, 16), (3301,)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the windows size features, combine 300 data as 1 points.\n",
    "Data_healthy, Lable_healthy = feature_process.window_feature_autoencoder(\n",
    "    healthy_df_train, 0, WIN_LEN, 4, 16\n",
    ")  # 200 =>0.87% #300 => 90%~92%(batch_size=256), #400 => 90%~92%(batch_size=128), #500 => 93%(batch_size=64)\n",
    "Data_broken, Lable_broken = feature_process.window_feature_autoencoder(broken_df_train, 1, WIN_LEN, 4, 16)\n",
    "print(f\"feature array shape of healthy point: {Data_healthy.shape}, {Lable_healthy.shape}\")\n",
    "print(f\"feature array shape of broken point: {Data_broken.shape}, {Lable_broken.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe109066-c18d-44e3-adba-4e3f33f3481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (5973, 16), (5973,)\n",
      "test data shape: (664, 16), (664,)\n"
     ]
    }
   ],
   "source": [
    "# Create the random 80% train and 20% test\n",
    "train_data, test_data, train_labels, test_labels = feature_process.concatenate_data(Data_healthy, Data_broken, Lable_healthy, Lable_broken, 0.1, 21)\n",
    "print(f\"train data shape: {train_data.shape}, {train_labels.shape}\")\n",
    "print(f\"test data shape: {test_data.shape}, {test_labels.shape}\")\n",
    "# save the max&min val\n",
    "max_val = tf.reduce_max(train_data)\n",
    "min_val = tf.reduce_min(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d43f9-d574-486d-a185-4d309dd5d30a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3d6bc-9d1a-40cb-b4d2-e1d1a746fb6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Autoencoder data prepare\n",
    "- Need to normalize the data\n",
    "- Need to sperate the data into normal and anomalous set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64ce1a04-74e8-4153-a2a7-1b127daae53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3158.1043774, shape=(), dtype=float64) tf.Tensor(-0.619863934954322, shape=(), dtype=float64)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "anomalous train data set: (3012, 16)\n",
      "normal train data set: (2961, 16)\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "train_data, test_data = feature_process.normalize_data_maxmin(train_data, test_data)\n",
    "print(type(train_data))\n",
    "\n",
    "# sperate to True & False for Autoencoder\n",
    "normal_train_data, anomalous_train_data = feature_process.normal_anomalous_distb(train_data, train_labels)\n",
    "normal_test_data, anomalous_test_data = feature_process.normal_anomalous_distb(test_data, test_labels)\n",
    "print(f\"anomalous train data set: {anomalous_train_data.shape}\")\n",
    "print(f\"normal train data set: {normal_train_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eb4d96-2932-4bb2-96c3-71ec2fc59ecb",
   "metadata": {},
   "source": [
    "## Autoencoder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb53b33c-788d-431c-bfcc-0b1f642b9f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376\n",
      "Trainable params: 376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_autoencoder(sample_shape):\n",
    "    \"\"\"\n",
    "    Creates and compiles an autoencoder model using TensorFlow and Keras.\n",
    "    Parameters:\n",
    "    sample_shape (tuple): The shape of the input samples.\n",
    "    Returns:\n",
    "    tf.keras.Sequential: The compiled autoencoder model.\n",
    "    \"\"\"\n",
    "    # sample_shape = normal_train_data[0].shape\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            layers.InputLayer(input_shape=sample_shape),\n",
    "            layers.Dense(8, activation=\"relu\"),\n",
    "            layers.Dense(4, activation=\"relu\"),\n",
    "            layers.Dense(4, activation=\"relu\"),\n",
    "            layers.Dense(8, activation=\"relu\"),\n",
    "            layers.Dense(*sample_shape, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Display model\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "    return model\n",
    "\n",
    "\n",
    "Autoen_model = create_autoencoder(normal_train_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc6fa198-2d11-480a-afd5-4f398da309c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4191 - val_loss: 0.4152\n",
      "Epoch 2/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4126 - val_loss: 0.4085\n",
      "Epoch 3/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 0.4011\n",
      "Epoch 4/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3979 - val_loss: 0.3930\n",
      "Epoch 5/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.3839\n",
      "Epoch 6/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 0.3643\n",
      "Epoch 7/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.3127\n",
      "Epoch 8/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.2743 - val_loss: 0.2236\n",
      "Epoch 9/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1792 - val_loss: 0.1302\n",
      "Epoch 10/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.0675\n",
      "Epoch 11/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0368\n",
      "Epoch 12/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0252\n",
      "Epoch 13/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0205\n",
      "Epoch 14/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0183\n",
      "Epoch 15/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0172\n",
      "Epoch 16/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0165\n",
      "Epoch 17/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0162\n",
      "Epoch 18/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 19/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0158\n",
      "Epoch 20/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 21/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0156\n",
      "Epoch 22/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 23/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 24/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0157\n",
      "Epoch 25/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 26/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 27/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0153\n",
      "Epoch 28/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 29/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 30/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 31/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0152\n",
      "Epoch 32/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0152\n",
      "Epoch 33/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0151\n",
      "Epoch 34/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0151\n",
      "Epoch 35/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 36/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 37/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 38/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 39/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 40/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 41/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 42/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 43/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0148\n",
      "Epoch 44/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 45/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 46/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 47/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 48/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 49/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 50/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 51/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 52/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 53/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 54/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0145\n",
      "Epoch 55/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 56/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 57/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 58/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 59/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 60/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 61/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 62/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 63/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 64/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 65/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 66/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 67/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 68/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 69/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 70/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 71/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0138\n",
      "Epoch 72/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0138\n",
      "Epoch 73/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 74/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 75/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 76/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 77/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 78/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 79/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0136\n",
      "Epoch 80/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0136\n",
      "Epoch 81/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 82/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 83/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0135\n",
      "Epoch 84/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 85/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 86/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 87/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 88/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 89/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 90/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 91/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 92/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 93/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 94/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 95/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 96/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 97/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 98/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 99/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 100/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 101/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 102/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.0130\n",
      "Epoch 103/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 104/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 105/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0129\n",
      "Epoch 106/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 107/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 108/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 109/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 110/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 111/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "Epoch 112/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 113/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 114/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 115/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 116/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 117/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 118/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 119/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 120/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 121/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 122/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 123/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 124/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 125/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 126/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 127/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 128/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 129/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 130/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 131/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 132/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 133/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 134/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 135/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 136/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 137/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 138/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 139/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 140/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 141/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 142/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 143/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 144/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 145/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 146/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 147/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 148/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 149/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 150/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 151/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 152/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 153/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 154/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 155/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 156/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 157/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 158/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 159/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 160/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 161/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 162/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 163/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 164/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 165/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 166/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 167/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 168/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 169/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 170/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 171/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 172/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 173/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 174/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 175/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 176/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 177/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 178/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 179/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 180/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 181/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 182/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 183/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 184/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 185/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 186/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 187/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 188/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 189/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 190/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 191/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 192/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 193/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 194/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 195/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 196/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 197/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 198/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 199/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 200/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 201/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 202/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 203/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 204/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 205/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 206/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 207/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 208/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 209/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 210/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 211/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 212/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 213/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 214/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 215/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 216/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 217/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 218/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 219/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 220/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 221/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 222/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 223/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 224/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 225/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 226/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 227/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 228/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 229/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 230/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 231/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 232/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 233/300\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 234/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 235/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 236/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 237/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 238/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 239/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 240/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 241/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 242/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 243/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 244/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 245/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 246/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 247/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 248/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 249/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 250/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 251/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 252/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 253/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 254/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 255/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 256/300\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 257/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 258/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 259/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 260/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 261/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 262/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 263/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 264/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 265/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 266/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 267/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 268/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 269/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 270/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 271/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 272/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 273/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 274/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 275/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 276/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 277/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 278/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 279/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 280/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 281/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 282/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 283/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 284/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 285/300\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 286/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 287/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 288/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 289/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 290/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 291/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 292/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 293/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 294/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 295/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 296/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 297/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 298/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 299/300\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 300/300\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0057\n"
     ]
    }
   ],
   "source": [
    "# Train model (note Y labels are same as inputs, X)\n",
    "def train_autoencoder(\n",
    "    m_epochs,\n",
    "    m_batch_size,\n",
    "    normal_train_data_autoencoder,\n",
    "    normal_test_data_autoencoder,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains an autoencoder model using the provided training and test data.\n",
    "    Parameters:\n",
    "    m_epochs (int): Number of epochs to train the model.\n",
    "    m_batch_size (int): Batch size to use during training.\n",
    "    normal_train_data_autoencoder (numpy.ndarray or tensorflow.data.Dataset)\n",
    "    normal_test_data_autoencoder (numpy.ndarray or tensorflow.data.Dataset)\n",
    "    Returns:\n",
    "    history_ae (tensorflow.python.keras.callbacks.History)\n",
    "    \"\"\"\n",
    "    history_ae = Autoen_model.fit(\n",
    "        normal_train_data_autoencoder, normal_train_data_autoencoder, epochs=m_epochs, batch_size=m_batch_size, \n",
    "        validation_data=(normal_test_data_autoencoder, normal_test_data_autoencoder), shuffle=True\n",
    "    )\n",
    "    return history_ae\n",
    "\n",
    "\n",
    "HISTORY = train_autoencoder(300, 128, normal_train_data, normal_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb5d20-f155-4d36-8c02-630fbaba7711",
   "metadata": {},
   "source": [
    "## Show the loss and decide threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eceb368-8d37-47d6-925a-559e2aa503df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 773us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cychen38\\AppData\\Local\\Temp\\ipykernel_50104\\1733330225.py:17: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  axes_sub = sns.lineplot(data=history_autoen.history[\"loss\"], ci=None, label=\"Training Loss\", ax=ax[0])\n",
      "C:\\Users\\cychen38\\AppData\\Local\\Temp\\ipykernel_50104\\1733330225.py:18: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  axes_sub = sns.lineplot(data=history_autoen.history[\"val_loss\"], ci=None, label=\"Validation Loss\", ax=ax[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 892us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.010711372829973698\n"
     ]
    }
   ],
   "source": [
    "def result_autoencoder(model_autoen, history_autoen, normal_data, anomalous_data):\n",
    "    \"\"\"\n",
    "    Visualizes the training and validation loss, and the loss distributions for normal and anomalous data.\n",
    "    Also calculates and returns the threshold for fault detection based on the model error.\n",
    "    Parameters:\n",
    "    model_autoen (tf.keras.Model): The trained autoencoder model.\n",
    "    history_autoen (tf.keras.callbacks.History): The history object containing training and validation loss.\n",
    "    normal_data (np.ndarray): The normal data used for training the autoencoder.\n",
    "    anomalous_data (np.ndarray): The anomalous data used for testing the autoencoder.\n",
    "    Returns:\n",
    "    float: The calculated threshold for fault detection.\n",
    "    \"\"\"\n",
    "\n",
    "    sns.set(style=\"darkgrid\")  # darkgrid, whitegrid, dark, white, ticks\n",
    "    _, ax = plt.subplots(1, 3, constrained_layout=True, figsize=(12, 4))\n",
    "\n",
    "    axes_sub = sns.lineplot(data=history_autoen.history[\"loss\"], ci=None, label=\"Training Loss\", ax=ax[0])\n",
    "    axes_sub = sns.lineplot(data=history_autoen.history[\"val_loss\"], ci=None, label=\"Validation Loss\", ax=ax[0])\n",
    "    axes_sub.set_xlabel(\"Epoch\")\n",
    "    axes_sub.set_ylabel(\"Loss\")\n",
    "    axes_sub.set_title(\"Train & Val loss\")\n",
    "\n",
    "    # For finding threshold to fault detection, histogram, of train loss and test loss was plotted\n",
    "    reconstructions = model_autoen.predict(normal_data)\n",
    "    train_loss = tf.keras.losses.mae(reconstructions, normal_data)\n",
    "    train_loss = np.array(train_loss)  # convert to np.array\n",
    "    axes_sub = sns.histplot(data=train_loss, ax=ax[1])\n",
    "    axes_sub.set_xlabel(\"Train loss\")\n",
    "    axes_sub.set_ylabel(\"No. of examples\")\n",
    "    axes_sub.set_title(\"Loss distribution of normal\")\n",
    "\n",
    "    reconstructions = model_autoen.predict(anomalous_data)\n",
    "    test_loss = tf.keras.losses.mae(reconstructions, anomalous_data)\n",
    "    # test_loss = tf.keras.losses.mse(reconstructions, anomalous_data)\n",
    "    test_loss = np.array(test_loss)  # convert to np.array\n",
    "    axes_sub = sns.histplot(data=test_loss, ax=ax[2])\n",
    "    axes_sub.set_xlabel(\"Train loss(anomalous)\")\n",
    "    axes_sub.set_ylabel(\"No. of examples\")\n",
    "    axes_sub.set_title(\"Loss distribution of anomalous\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # threshold for fault detection based on model error\n",
    "    th = np.mean(train_loss) + 2 * np.std(train_loss)\n",
    "    print(\"Threshold: \", th)\n",
    "    return th\n",
    "\n",
    "\n",
    "threshold = result_autoencoder(Autoen_model, HISTORY, normal_train_data, anomalous_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af598c2-0a90-4991-ac75-a74f3cbfb641",
   "metadata": {},
   "source": [
    "## Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e505bf08-db4c-4d87-8449-3636490eb537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data number: 664\n",
      "Accuracy = 0.9186746987951807\n",
      "Precision = 0.8864864864864865\n",
      "Recall = 0.9647058823529412\n",
      "Train Data number: 5973\n",
      "Accuracy = 0.9104302695462917\n",
      "Precision = 0.8746139592340951\n",
      "Recall = 0.9564336372847011\n"
     ]
    }
   ],
   "source": [
    "def predict(model, data2predict, th):\n",
    "    \"\"\"\n",
    "    Predicts whether the reconstruction loss of the data is below a given threshold.\n",
    "    \"\"\"\n",
    "    reconstructions = model(data2predict)\n",
    "    return tf.math.less(tf.keras.losses.mae(reconstructions, data2predict), th)\n",
    "\n",
    "\n",
    "def print_stats(predictions, labels):\n",
    "    \"\"\"\n",
    "    Prints the accuracy, precision, and recall of the given predictions compared to the true labels.\n",
    "    Parameters:\n",
    "    predictions (array-like): The predicted labels.\n",
    "    labels (array-like): The true labels.\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(f\"Accuracy = {accuracy_score(labels, predictions)}\")\n",
    "    print(f\"Precision = {precision_score(labels, predictions)}\")\n",
    "    print(f\"Recall = {recall_score(labels, predictions)}\")\n",
    "\n",
    "\n",
    "# accuracy\n",
    "print(f\"Test Data number: {test_data.shape[0]}\")\n",
    "preds = predict(Autoen_model, test_data, threshold)\n",
    "print_stats(preds, test_labels)\n",
    "\n",
    "print(f\"Train Data number: {train_data.shape[0]}\")\n",
    "preds = predict(Autoen_model, train_data, threshold)\n",
    "print_stats(preds, train_labels)\n",
    "\n",
    "# accuracy for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ea85c-cdc6-41d9-8183-50e54100df4f",
   "metadata": {},
   "source": [
    "## Show MCU Inference Result first\n",
    "- This dataset is for MCU inference latter, and we use PC python to inference first.\n",
    "- The `Accuracy` value should be almost same as MCU result latter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee349dcf-bd35-4b10-b8f2-492e52df9258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature array shape of test healthy point: (50, 16), (50,)\n",
      "feature array shape of test broken point: (50, 16), (50,)\n",
      "tf.Tensor(3158.1043774, shape=(), dtype=float64) tf.Tensor(-0.619863934954322, shape=(), dtype=float64)\n",
      "Test Data number: 100\n",
      "Accuracy = 0.92\n",
      "Precision = 0.8888888888888888\n",
      "Recall = 0.96\n"
     ]
    }
   ],
   "source": [
    "# accuracy for MCU inference data\n",
    "# calculate feature\n",
    "Data_healthy_test, Lable_healthy_test = feature_process.window_feature_autoencoder(\n",
    "    healthy_df_test, 0, WIN_LEN, 4, 16\n",
    ")  # 200 =>0.87% #300 => 90%~92%(batch_size=256), #400 => 90%~92%(batch_size=128), #500 => 93%(batch_size=64)\n",
    "Data_broken_test, Lable_broken_test = feature_process.window_feature_autoencoder(broken_df_test, 1, WIN_LEN, 4, 16)\n",
    "print(f\"feature array shape of test healthy point: {Data_healthy_test.shape}, {Lable_healthy_test.shape}\")\n",
    "print(f\"feature array shape of test broken point: {Data_broken_test.shape}, {Lable_broken_test.shape}\")\n",
    "inference_data = np.concatenate([Data_healthy_test, Data_broken_test], axis=0)\n",
    "inference_label = np.concatenate([Lable_healthy_test, Lable_broken_test], axis=0)\n",
    "\n",
    "# normalize\n",
    "print(max_val, min_val)\n",
    "inference_data = (inference_data - min_val) / (max_val - min_val)\n",
    "inference_data = tf.cast(inference_data, tf.float32)\n",
    "\n",
    "print(f\"Test Data number: {inference_data.shape[0]}\")\n",
    "preds = predict(Autoen_model, inference_data, threshold)\n",
    "print_stats(preds, inference_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca61f16-53d9-42c6-8b80-ebabef2a29a3",
   "metadata": {},
   "source": [
    "# TensorFlow Lite Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b98d73",
   "metadata": {},
   "source": [
    "### 1. Save as saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b04b1454-7715-408a-9161-bb100a03c873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: autoencoder\\assets\n"
     ]
    }
   ],
   "source": [
    "# If we're happy with the performance, save the model\n",
    "ori_model = Autoen_model\n",
    "KERAS_MODEL_NAME = \"autoencoder\"\n",
    "\n",
    "tf.saved_model.save(ori_model, KERAS_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a9bf7",
   "metadata": {},
   "source": [
    "### 2. Save as TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9db7e770-4dd7-4cae-8383-5422c04cd31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\cychen38\\AppData\\Local\\Temp\\tmp58td97vk\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4400"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(ori_model)\n",
    "tflite_model = converter.convert()\n",
    "open(os.path.join(KERAS_MODEL_NAME, (KERAS_MODEL_NAME + \".tflite\")), \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4054a9b",
   "metadata": {},
   "source": [
    "### 3. Convert TFLite to C++ file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a8b9209-2c45-4b7d-abd7-748540fa7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite_to_tflu(*, models_path, c_model_name, keras_model_name, th, max_v, min_v):\n",
    "    \"\"\"\n",
    "    Converts a TensorFlow Lite model to a TensorFlow Lite Micro model and saves it as a C source file.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    tflite_name = os.path.join(keras_model_name, (keras_model_name + \".tflite\"))\n",
    "    my_f_name = os.path.join(models_path, c_model_name) + \".cc\"\n",
    "    ! python tflite_to_tflu_para.py --tflite_path $tflite_name --output_path $my_f_name --window_size_sample $WIN_LEN --max_val_train $max_v --min_val_train $min_v --threshold_val $th\n",
    "\n",
    "\n",
    "MODELS_PATH = \"model\"\n",
    "C_MODEL_NAME = r\"Gearbox_fault_\" + KERAS_MODEL_NAME\n",
    "tflite_to_tflu(models_path=MODELS_PATH, c_model_name=C_MODEL_NAME, keras_model_name=KERAS_MODEL_NAME, th=threshold, max_v=max_val.numpy(), min_v=min_val.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37b7aa-8fd7-4df9-b91c-1d8fac640451",
   "metadata": {},
   "source": [
    "# Convert to int8 TFLite and testing\n",
    "- Int8 full quantization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94ef03",
   "metadata": {},
   "source": [
    "### 1. Save as Int8 TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8eb5d09e-8ec6-42c9-a557-9441e2417190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\cychen38\\AppData\\Local\\Temp\\tmpmoitwb22\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\cychen38\\AppData\\Local\\Temp\\tmpmoitwb22\\assets\n",
      "c:\\ProgramData\\miniforge3\\envs\\NuEdgeWise_env\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3984"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "NUM_REP_DATA_SAMPLES = 300\n",
    "\n",
    "\n",
    "def _rep_dataset():\n",
    "    \"\"\"Generator function to produce representative dataset.\"\"\"\n",
    "    for idx in range(len(normal_train_data)):\n",
    "        if idx >= NUM_REP_DATA_SAMPLES:\n",
    "            break\n",
    "        yield [tf.dtypes.cast(train_data[idx], tf.float32)]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(ori_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "converter.representative_dataset = _rep_dataset\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_model = converter.convert()\n",
    "open(os.path.join(KERAS_MODEL_NAME, (KERAS_MODEL_NAME + \"_int8quantized.tflite\")), \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e25ad",
   "metadata": {},
   "source": [
    "### 2. Test the Int8 TFLite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5168c0c2-ca31-4b23-a71b-2f34d35c38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite_inference(input_data, inf_tflite_path):\n",
    "    \"\"\"Call forwards pass of TFLite file and returns the result.\n",
    "\n",
    "    Args:\n",
    "        input_data: Input data to use on forward pass.\n",
    "        inf_tflite_path: Path to TFLite file to run.\n",
    "\n",
    "    Returns:\n",
    "        Output from inference.\n",
    "    \"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_path=inf_tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    input_dtype = input_details[0][\"dtype\"]\n",
    "    output_dtype = output_details[0][\"dtype\"]\n",
    "\n",
    "    # Check if the input/output type is quantized,\n",
    "    # set scale and zero-point accordingly\n",
    "    if input_dtype == np.int8:\n",
    "        input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "    else:\n",
    "        input_scale, input_zero_point = 1, 0\n",
    "\n",
    "    input_data = input_data / input_scale + input_zero_point\n",
    "    input_data = np.round(input_data) if input_dtype == np.int8 else input_data\n",
    "\n",
    "    if output_dtype == np.int8:\n",
    "        output_scale, output_zero_point = output_details[0][\"quantization\"]\n",
    "    else:\n",
    "        output_scale, output_zero_point = 1, 0\n",
    "\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], tf.cast(input_data, input_dtype))\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    output_data = output_scale * (output_data.astype(np.float32) - output_zero_point)\n",
    "\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ce17933-b84b-4016-88a7-e91b7da3e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_path = os.path.join(KERAS_MODEL_NAME, (KERAS_MODEL_NAME + \"_int8quantized.tflite\"))\n",
    "\n",
    "predicted_indices = []\n",
    "for data, label in zip(test_data, test_labels):  # pylint: disable=unused-variable\n",
    "    prediction = tflite_inference(tf.expand_dims(data, axis=0), tflite_path)\n",
    "    predicted_indices.append(prediction)\n",
    "predicted_indices = tf.convert_to_tensor(np.vstack(predicted_indices), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd7a23b6-e3e4-4869-ad4a-db927d2ca6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9141566265060241\n",
      "Precision = 0.8834688346883469\n",
      "Recall = 0.9588235294117647\n"
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.mae(predicted_indices, test_data)\n",
    "preds = tf.math.less(loss, threshold)\n",
    "print_stats(preds, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff09555",
   "metadata": {},
   "source": [
    "### 3. Convert TFLite to C++ file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ebbf476",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = \"model\"\n",
    "C_MODEL_NAME = r\"Gearbox_fault_\" + KERAS_MODEL_NAME + r\"_int8quantized\"\n",
    "tflite_to_tflu(models_path=MODELS_PATH, c_model_name=C_MODEL_NAME, keras_model_name=KERAS_MODEL_NAME, th=threshold, max_v=max_val.numpy(), min_v=min_val.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5099be-c0ac-462d-aab3-7475ca3a3666",
   "metadata": {},
   "source": [
    "# Convert the test data to C code\n",
    "- This data set is after preprocessed.\n",
    "- Just used to make sure the model is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caaf7ad2-d081-491d-8042-3a6e98a600b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many_test = test_data.shape[0]\n",
    "\n",
    "Xtest = test_data.numpy()[:how_many_test, :]  # transfer to nparray\n",
    "\n",
    "Xtest_str = c_writer.create_array(Xtest, \"float\", \"X_test\")\n",
    "\n",
    "ytest = test_labels[:how_many_test].astype(int)\n",
    "ytest_str = c_writer.create_array(ytest, \"uint8_t\", \"y_test\")\n",
    "\n",
    "test_d = Xtest_str + ytest_str\n",
    "\n",
    "header_test_d = c_writer.create_header(test_d, \"gearbox_test_data\")\n",
    "with open(os.path.join(\"data\", \"gearbox_test_data\") + \".h\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(header_test_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a61e18-035f-43cf-8faf-c47514672757",
   "metadata": {},
   "source": [
    "# Convert the raw data to C code\n",
    "- This data is raw data, for edge device to inference.\n",
    "- It is a more realistic case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa534c9b-3b8b-4f25-8107-c584540584af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data size is: 30000\n",
      "The raw label size is: 100\n"
     ]
    }
   ],
   "source": [
    "def save_test_data_in_c(data_x, label_y):\n",
    "    \"\"\"\n",
    "    Saves test data and labels into a C header file.\n",
    "    This function takes test data and labels, converts them into C arrays,\n",
    "    and writes them into a header file named 'gearbox_raw_test_data.h' in the 'data' directory.\n",
    "    Args:\n",
    "        data_x (numpy.ndarray): The test data to be saved.\n",
    "        label_y (numpy.ndarray): The labels corresponding to the test data.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    xtest_str = c_writer.create_array(data_x, \"float\", \"X_test\", 1)\n",
    "\n",
    "    test_label_data = label_y.astype(int)\n",
    "    test_label_data_str = c_writer.create_array(test_label_data, \"uint8_t\", \"y_test\")\n",
    "\n",
    "    test_str = xtest_str + test_label_data_str\n",
    "\n",
    "    header_test_writed = c_writer.create_header(test_str, \"gearbox_raw_test_data\")\n",
    "    with open(os.path.join(\"data\", \"gearbox_raw_test_data\") + \".h\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(header_test_writed)\n",
    "\n",
    "\n",
    "raw_data = np.concatenate([healthy_df_test, broken_df_test], axis=0)\n",
    "raw_label = np.concatenate([Lable_healthy_test, Lable_broken_test], axis=0)\n",
    "print(f\"The raw data size is: {len(raw_data)}\")\n",
    "print(f\"The raw label size is: {len(raw_label)}\")\n",
    "save_test_data_in_c(raw_data[:, 0:4], raw_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NuEdgeWise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
